function [theta,z,beta,L,i]=LDA_VI(lambda,gamma,phi,W,alpha,eta,beta,...
    thresh,iter)

% This function applies LDA (latent Dirichlet allocation) with mean-field
% variational inference.
%
% Terminology:
%   K -- number of topics
%   D -- number of documents
%   V -- vocabulary size
%
% Input (can specify initial values):
%   lambda -- attached parameter to topics (K-by-V)
%   gamma -- attached parameter to per-document topic propotions (D-by-K)
%   phi -- attached parameter to per-word topic assignment (D-by-V-by-K)
%   W -- observed documents (D-by-V)
%   alpha -- parameter for V-dimensional Dirichlet distribution (K-by-1)
%   eta -- parameter for K-dimensional Dirichlet distribution (1-by-1)
%   beta -- topic distribution among words (K-by-V)
%   thresh -- program stops when improvement on the evidence lower bound is
%             less than this value
%   iter -- program stops when the maximum number of iterations achieves
%           this value
%
% Output:
%   beta -- topic distribution among words (K-by-V)
%   theta -- per-document topic propotions (D-by-K)
%   z -- per-word topic assignment (D-by-N-by-K)
%   L -- the evidence lower bound w.r.t. iterations
%   i -- number of iterations
%
% Author: Z. Luo
% Date: December 2015

% Run iterations with mean-field variational inference.
change=inf;
i=0;
L=ELB(gamma,phi,alpha,beta);
while(change>thresh)
    if(i>=iter)
        break;
    end
    [lambda,gamma,phi]=MFVar(lambda,gamma,phi,W,alpha,eta);
    % The (n)th entry is the lower bound after the (n-1)th iteration.
    L(i+2)=ELB(gamma,phi,alpha,beta);
    change=L(i+2)-L(i+1);
    i=i+1;
end

%update alpha and beta
for topic=1:K
    var_params.alpha(topic,:)=sum(var_params.gamma(:,topic));
    var_params.beta(:,topic)=var_params.lambda(topic,:)/sum(var_params.lambda(topic,:));
end    

%update topic assignments
for d=1:D
    wdn_idx=find(A(:,d));
    for i=1:length(wdn_idx)
       [~,z_idx]=max(var_params.phi(d,wdn_idx(i),:));
       var_params.z(i,d)=z_idx;
    end
end








end